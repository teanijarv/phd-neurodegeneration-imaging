{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import savemat\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from connectomics.atlases import fetch_dk_atlas, get_dk_hemisphere_mask\n",
    "from connectomics.connectivity import merge_connectomes\n",
    "from utils.transform import minmax_scale_data\n",
    "\n",
    "# in\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'data'))\n",
    "\n",
    "df_dir = os.path.join(data_dir, 'datasets')\n",
    "masks_dir = os.path.join(data_dir, 'masks')\n",
    "\n",
    "df_fname = os.path.join(df_dir, 'bf2_tau_asymmetry_ad_t_xs_tnic_fnc_mri.csv')\n",
    "\n",
    "# out\n",
    "nbs_in_dir = os.path.join(data_dir, 'nbs', 'in')\n",
    "os.makedirs(nbs_in_dir, exist_ok=True)\n",
    "nbs_out_dir = os.path.join(data_dir, 'nbs', 'out')\n",
    "os.makedirs(nbs_out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Desikan-Killiany atlas\n",
    "dk_img, dk_labels, dk_coords = fetch_dk_atlas(coords=True)\n",
    "\n",
    "# save atlas coordinates and labels\n",
    "np.savetxt(os.path.join(nbs_in_dir, 'dk_coords.txt'), dk_coords)\n",
    "with open(os.path.join(nbs_in_dir, 'dk_labels.txt'), 'w') as f:\n",
    "        for label in list(dk_labels.keys()):\n",
    "                f.write(f\"{label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_perc = 90\n",
    "modality = 'fc' # 'sc'\n",
    "corr_type = f'dk_{modality}_file'\n",
    "mask_type = f'dk_n_{modality}_mask'\n",
    "grp_col = 'temporal_meta_tau_asymmetry_group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying and exporting correlation matrices with no_mask\n",
      "Applying and exporting correlation matrices with normal_mask_90\n",
      "Data shape (A): (103, 3195)\n",
      "Data shape (LA): (73, 3195)\n",
      "Data shape (S): (215, 3195)\n",
      "Data shape (RA): (30, 3195)\n"
     ]
    }
   ],
   "source": [
    "# load normative masks\n",
    "no_mask = get_dk_hemisphere_mask(dk_labels, 'full') #np.ones((len(dk_labels), len(dk_labels)))\n",
    "interhemi_mask = get_dk_hemisphere_mask(dk_labels, 'interhemi') #np.ones((len(dk_labels), len(dk_labels)))\n",
    "hc_normative_mask = np.load(os.path.join(masks_dir, f'{mask_type}_{mask_perc}.npy'))\n",
    "\n",
    "# Read the datasets for AD and HC groups\n",
    "df_ad = pd.read_csv(df_fname, index_col=0, low_memory=False)\n",
    "\n",
    "# leave only ones with MRI\n",
    "df_ad = df_ad[~df_ad[corr_type].isna()]\n",
    "\n",
    "# Create dataframes for each of the asymmetry groups\n",
    "df_A = df_ad[df_ad[grp_col].isin(['LA', 'RA'])].reset_index(drop=True)\n",
    "df_LA = df_ad[df_ad[grp_col]=='LA'].reset_index(drop=True)\n",
    "df_S = df_ad[df_ad[grp_col]=='S'].reset_index(drop=True)\n",
    "df_RA = df_ad[df_ad[grp_col]=='RA'].reset_index(drop=True)\n",
    "\n",
    "all_masks = {\n",
    "    f'no_mask' : no_mask,\n",
    "    f'normal_mask_{mask_perc}' : hc_normative_mask,\n",
    "}\n",
    "\n",
    "if corr_type == 'dk_fc_file': \n",
    "    drop_first_roi = True # labels in FC matrix to be removed\n",
    "    fisher = True # apply fisher r-to-z\n",
    "    replace_nan_with = None\n",
    "elif corr_type == 'dk_sc_file': \n",
    "    drop_first_roi = False\n",
    "    fisher = False\n",
    "    replace_nan_with = None\n",
    "elif corr_type == 'dk_fa_file' or corr_type == 'dk_md_file':\n",
    "    drop_first_roi = False\n",
    "    fisher = False\n",
    "    replace_nan_with = 0\n",
    "\n",
    "conn_params = dict(connectome_path_col=corr_type, drop_first_roi=drop_first_roi, \n",
    "                   fisher=fisher, replace_nan_with=replace_nan_with, verbose=True)\n",
    "\n",
    "for mask_name, mask in all_masks.items():\n",
    "    print(f\"Applying and exporting correlation matrices with {mask_name}\")\n",
    "    df_A, connectomes_A = merge_connectomes(df_A, mask=mask, **conn_params)\n",
    "    df_LA, connectomes_LA = merge_connectomes(df_LA, mask=mask, **conn_params)\n",
    "    df_S, connectomes_S = merge_connectomes(df_S, mask=mask, **conn_params)\n",
    "    df_RA, connectomes_RA = merge_connectomes(df_RA, mask=mask, **conn_params)\n",
    "\n",
    "    savemat(os.path.join(nbs_in_dir, f'{corr_type}_A_{mask_name}.mat'), \n",
    "            {f'{corr_type}_A': connectomes_A})\n",
    "    savemat(os.path.join(nbs_in_dir, f'{corr_type}_LA_{mask_name}.mat'), \n",
    "            {f'{corr_type}_LA': connectomes_LA})\n",
    "    savemat(os.path.join(nbs_in_dir, f'{corr_type}_S_{mask_name}.mat'), \n",
    "            {f'{corr_type}_S': connectomes_S})\n",
    "    savemat(os.path.join(nbs_in_dir, f'{corr_type}_RA_{mask_name}.mat'), \n",
    "            {f'{corr_type}_RA': connectomes_RA})\n",
    "\n",
    "print(f\"Data shape (A): {df_A.shape}\")\n",
    "print(f\"Data shape (LA): {df_LA.shape}\")\n",
    "print(f\"Data shape (S): {df_S.shape}\")\n",
    "print(f\"Data shape (RA): {df_RA.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_col = 'tnic_global'\n",
    "\n",
    "# Create a subset of design matrix of covariates\n",
    "df_design_A = df_A[['age', 'gender_baseline_variable', tau_col]].copy()\n",
    "df_design_A[['age', tau_col]] = minmax_scale_data(df_design_A, ['age', tau_col])\n",
    "design_mat_A = df_design_A.to_numpy()\n",
    "savemat(os.path.join(nbs_in_dir, f'covars_{modality}_A.mat'), \n",
    "        {f'covars_A': design_mat_A})\n",
    "\n",
    "df_design_LA = df_LA[['age', 'gender_baseline_variable', tau_col]].copy()\n",
    "df_design_LA[['age', tau_col]] = minmax_scale_data(df_design_LA, ['age', tau_col])\n",
    "design_mat_LA = df_design_LA.to_numpy()\n",
    "savemat(os.path.join(nbs_in_dir, f'covars_{modality}_LA.mat'), \n",
    "        {f'covars_LA': design_mat_LA})\n",
    "\n",
    "df_design_RA = df_RA[['age', 'gender_baseline_variable', tau_col]].copy()\n",
    "df_design_RA[['age', tau_col]] = minmax_scale_data(df_design_RA, ['age', tau_col])\n",
    "design_mat_RA = df_design_RA.to_numpy()\n",
    "savemat(os.path.join(nbs_in_dir, f'covars_{modality}_RA.mat'), \n",
    "        {f'covars_RA': design_mat_RA})\n",
    "\n",
    "df_design_S = df_S[['age', 'gender_baseline_variable', tau_col]].copy()\n",
    "df_design_S[['age', tau_col]] = minmax_scale_data(df_design_S, ['age', tau_col])\n",
    "design_mat_S = df_design_S.to_numpy()\n",
    "savemat(os.path.join(nbs_in_dir, f'covars_{modality}_S.mat'), \n",
    "        {f'covars_S': design_mat_S})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
